q_loss,P09:episode_rewards,grad_norm,policy_loss,model_prob_std,PMM:episode_rewards,policy_entropy,rollout_prob_std,epoch_idx,advantage_norm,policy_gradient_loss,P01:episode_rewards,avg_q_retraced,avg_q_selected,fps,frames,policy_gradient_bias_correction,explained_variance,episode_length
0.00016843680020125855,0.0,0.03241941756790627,-3.0510401438732514e-05,0.008218315724904338,0.0,2.1889830668767294,0.008218315655055146,1,0.0439908513178428,-3.0510401438732514e-05,0.0,-0.007536492170765996,-0.007161447592079639,253,7200,0.0,-10.418664089838664,0
