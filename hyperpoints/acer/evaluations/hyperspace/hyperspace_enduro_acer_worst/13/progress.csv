policy_entropy,q_loss,explained_variance,policy_gradient_loss,frames,advantage_norm,P01:episode_rewards,episode_length,P09:episode_rewards,model_prob_std,avg_q_retraced,avg_q_selected,policy_loss,policy_gradient_bias_correction,grad_norm,fps,rollout_prob_std,PMM:episode_rewards,epoch_idx
2.192602300643921,6.417680991338178e-05,-12.658796246846517,0.00010483130527821534,7200,0.03460410286982854,0.0,0,0.0,0.006651640838632981,-0.00539918909004579,-0.005344609015931686,0.00010483130527821534,0.0,0.024905999201076893,349,0.00665164062132438,0.0,1
